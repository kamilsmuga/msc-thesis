\documentclass[]{final_report}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{csvsimple}
\usepackage{float}
\usepackage[]{algorithm2e}
\usepackage{url}


\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}

%%%%%%%%%%%%%%%%%%%%%%
%%% Project details
%%%%%%%%%%%%%%%%%%%%%%
\def\studentname{Kamil Smuga}
\def\projecttitle{An approach for Continuous Capacity Planning in Cloud Environments with an Uptime-based Pricing Model}
\def\supervisorname{Prof. Liam Murphy}
\def\moderatorname{Christina Thorpe}

\begin{document}

\maketitle
\tableofcontents\pdfbookmark[0]{Table of Contents}{toc}\newpage
\listoffigures\newpage
\par{\textbf{List of tables}}

%%%%
%The most important parts of your thesis are: abstract, introduction, conclusion and
%references. These are what get read first and make that vital initial impression.
%%%
%%%
%One of first things your examiners will look at is your literature review. If they see a
%good number of journal papers, a swathe of conference papers, a few recent workshop
%papers and not too many web sites, theyâ€™ll already be impressed.
%%%
%%%%%%%%%%%%%%%%%%%%%%
%%% ABSTRACT 
%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

\emph{ /* To be revised. */} \par
\textsl{New Infrastructure as a Service solutions are becoming available with a growing number of supported pricing models. More often than not, a hosted Cloud environment is used to design and build an infrastructure for a product. The recent availability of different pricing schemes based on resource utilization and uptime reveals new challenges in already unpredictable capacity planning process. There is a choice between ad-hoc provisioning and upfront payments with reduced hourly rates. Reserved instances charged upfront are categorized into three groups: light, medium and heavy. Which one is better for a given utilization model? When exactly does one pricing scheme becomes more cost effective? Determining which machine type is better for a given utilization model, or at which point the cost effectiveness of a pricing scheme changes, is vital for the companies subscribing to the IaaS. }

\end{abstract}
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% INTRODUCTION 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\emph{ /* Type of the project: The 'Big Idea' / proof by construction. */}

\section{Description of the problem}

\section{Motivation for solving the problem}

\section{Objectives}
This work aims to design an algorithm that answer IaaS consumer's price optimality questions and help to make adjustments based on uptime based charging per machine. 

\section{Related work}

\section{Challenges}

\section{Description of methodology}
Modelling and experimentation

\section{Structure of the Thesis}
\textbf{Background}. This section will outline the background information related to IaaS consumer challenges related to understanding the whole picture for price optimality of rented infrastructure. \par
\textbf{Design}. This section explains design and environment conditions for the algorithm to be useful. \par
\textbf{Implementation}. This sections explains algorithm implementation details and data analytics software that was used - Apache Spark~\cite{spark}. \par
\textbf{Evaluation}. The proposed algorithmic approach is applied on Google Trace data~\cite{googleTrace}. \par
\textbf{Conclusion and Further Work}. The completed data analysis is discussed. Further work related to algorithm improvements, automation and lessons learned are presented. 
 
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% BACKGROUND 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Background}

\section{The Problem Domain}
\emph{/* Description of IaaS world - providers and consumers. */}
\subsection{IaaS consumer point of view}
\subsection{IaaS provider uptime-based pricing schemes}

\section{Motivation}
\emph{ /* Description of the problem - cloud based company runs a mix of software services (real-time streaming, batch, web and database servers) on common hardware. How do they know whether provisioned VMs run in the most optimal configuration? */ }

\section{Literature review}
\emph{/* Haven't found anything that would tackle this specific problem so far. Might mention the most research is done from IaaS provider perspective? This includes resource scheduling. My work can lead to cost-aware scheduler research */}

%good number of journal papers, a swathe of conference papers, a few recent workshop
%papers and not too many web sites


%%%%%%%%%%%%%%%%%%%%%%
%%% DESIGN 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Design and Implementation}

\section{Taxonomy}

\subsection{Upfront cost}

Investment in compute resources comes with upfront cost. In case of physical machine it is hardware or lease cost. For virtual resources, IaaS providers offer per hour discounts for upfront charged schemes. \par
Upfront cost is considered to be one time payment and will be represented by \textit{u}. 

\subsection{Cost per hour}

Cost per hour represents a total cost of running a single machine divided by number of hours in calendar year. Aggregated cost is relatively easy to calculate in rented, virtualised environments. IaaS providers usually charge an X amount per hour. It might vary based on total uptime per month or pricing scheme. This number will be considered as a partial cost per hour and defined as \textit{pcph}. \par
Cost of running of physical hardware is less straightforward to calculate as it includes: power consumption, operations, hardware replacements cost, data center related costs and many others that may vary based on individual cases. Although more troublesome to calculate, cost per hour per host for physical infrastructure is possible to calculate. \par
Cost per hour will be defined as \textit{cph}. It includes upfront cost and IaaS provider per hour charges. It is defined as a function of hours of utilization per day.  

\begin{equation}
cph(h) = \frac{u + \sum_{i=1}^{366} pcph \times h}{365 \times h}
\end{equation}

\subsection{Intersection points between pricing schemes}

Cost per hour is calculated for each of available pricing schemes. Single result represents a matrix of hours per day and \textit{cph}. Graphical representation of results produces a graph similar to Figure~\ref{fig:cc2_8xlarge}. \par 
This representation allows to notice pricing trends. In the example below, price drops exponentially for around first 5 hours of usage and nearly stabilizes afterwards. Light is the cheapest option for around 15 hours per day usage. This is better visible on Figure~\ref{fig:cph_cc2_8xlarge_zoom}. After 15 hours, it is better to invest in Heavy utilization scheme. This is the point that will be called \textit{an intersection point} between 2 pricing schemes and noted as \textit{ip(scheme1, scheme2)}. \par
For the example below, cc2.8xlarge instance's intersection point between Light and Heavy schemes is \textit{ip(light, heavy) = 16}.

\begin{figure}[H]
	\includegraphics[width=\linewidth]{figures/cc2_8xlarge}
	\caption{\textit{cph} results for Amazon AWS cc2.8xlarge reserved instance rented for 1 year~\cite{AWS:2014}}
	\label{fig:cc2_8xlarge}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{figures/cph_cc2_8xlarge_zoom}
	\caption{Zoomed \textit{cph} results for Amazon AWS cc2.8xlarge reserved instance rented for 1 year~\cite{AWS:2014}}
	\label{fig:cph_cc2_8xlarge_zoom}
\end{figure}


\section{Algorithm}

\subsection{Prerequisites} 

In order to make data-driven analysis and suggestions for optimization we need data. Below list of metrics was compiled based on algorithm needs to answer critical questions regarding state of infrastructure deployment. The list is suitable to guarantee performance SLOs only for compute nodes. Machines with significant I/O usage profile are not covered in this paper. 
Metrics can be gathered periodically, per process or per job. There are open source tools available to gather this data, e.g. collectd\footnote{\url{https://collectd.org}}, munin\footnote{\url{http://munin-monitoring.org}}, Logstash\footnote{\url{http://logstash.net}}.

\myparagraph{Machine Id}
A unique machine ID. Will be used as a key to compute further analytics.

\myparagraph{Start and End Time}
Timestamps to indicate start and end of measurement period.

\myparagraph{CPU usage}
Sampled or averaged CPU usage during measurement period. 

\myparagraph{RAM usage}
Canonical memory usage measurement. 

Metrics should be aggregated in \textless K, List\textless V\textgreater\textgreater format where K represents Machine Id and Vs are measurements. 

\subsection{Metrics data transformations and analytics}

Metrics gathered in Prerequisites section have limited knowledge about an environment. Collection per job or per process produces one log line and is aware only about measurement period. Having such structured data would not let to answer machine wide neither cluster wide questions. The data has to be post-processed to allow calculation of below listed analytics.   



\myparagraph{Uptime per machine}

\begin{algorithm}[H]
 \KwData{Task start and end time}
 \KwResult{Number of uptime hours per machine per day}
\end{algorithm}

Input: Job start and end time logged for each machine in a form of \textless K, List\textless V\textgreater\textgreater

Output: Uptime based on span between min start time and max end time \textless K,V\textgreater

\myparagraph{Aggregate CPU and memory usage}
Input: Sampled CPU and memory usage logged per job in a form of \textless K, List\textless V\textgreater\textgreater

Output: Aggregated resource usage \textless K,V\textgreater

\myparagraph{Calculate number of jobs per day}
Input: Job id per machine \textless K, List\textless V\textgreater\textgreater

Output: Job count per machine \textless K,V\textgreater

\myparagraph{Calculate cluster averages for aggregations}
Input: Aggregated CPU, memory and number of tasks per machine per day \textless K, List\textless V\textgreater\textgreater

Output: Averages for CPU, memory and number of tasks \textless K, List\textless V\textgreater\textgreater

\myparagraph{Calculate distance from optimality points based on uptime}
Input: Machine uptime per day

Output: Distance from optimality points. Might be positive or negative. 

\subsubsection{Calculate cost per hour for a given pricing scheme}

\begin{algorithm}[H]
 \KwData{Upfront cost, Per hour charge, Utilization [hours per day];}
 \KwResult{Total cost per hour for a given pricing scheme defined as \textit{cph};}
 read upfront\;
 read perhour\;
 read hours\;	
 return (upfront + (365 * perhour * hours)) / (365 * hours)
 \caption{Calculate cost per hour for a given pricing scheme}
\end{algorithm}

\subsubsection{Calculate intersection points to find out the best pricing scheme for a number of hours/day utilization}

\begin{algorithm}[H]
 \KwData{Array of cph for 2 pricing schemes;}
 \KwResult{Intersection point when one pricing scheme becomes cheaper than the other one;}
 read array1\;
 read array2\;
 \ForAll{cph in array} {
 	\If{$cph2 <= $cph1} {
 		return cph
 	}
 }
\caption{Calculate intersection point between two pricing schemes}
\end{algorithm}




\subsection{Recognize inefficiencies and suggest changes}

\subsubsection{Threshold based report}

Generate report of machines based on distance from optimality points. Use customizable threshold. 
Results from the report will be used to calculate suggestions.

\subsubsection{Visual recognition}

Visual recognition as a helper method to define thresholds, especially for further incremental optimizations. 
Useful as static thresholds can miss a whole set of machines that are just below the threshold. 


\begin{figure}[H]
       \includegraphics[width=\linewidth]{figures/cubism}
      \caption{Visualization of distance from optimality points. Green - positive, Blue - negative values.}
        \label{fig:cubism}
\end{figure}

\subsubsection{Squeeze-them-in suggestion strategy}

Input: results of the Threshold based report. 

Computation: Calculate spare capacity based on average CPU and memory usage. Iterate through a pool of available machines (not included in input report) and advertise available capacity only if CPU and memory usage is lower than average. Aggregate spare capacity results.

Output: List of machines that can be shutdown based on computed spare-capacity.

\subsubsection{New capacity configuration suggestion}

Input: results of the Threshold based report.

Computation: Compute a minimal number of VMs for each configuration based on requested capacity

Output: A number and configuration of the cheapest computed configuration.

%%%%%%%%%%%%%%%%%%%%%%
%%% IMPLEMENTATION 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}

\emph{/* Implementation quirks related to make it work. Mostly map/reduce jobs written for Apache Spark. */}

%%%%%%%%%%%%%%%%%%%%%%Â Â 
%%% EVALUATION!!!
%%% ALGORITHM TESTING  
%%% ON GOOGLE DATASET 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}

\emph{/* Evaluation will go through each of Design stages and will perform necessary calculations. Some examples attached below. */}

\subsection{Recognize inefficiencies and suggest changes}

\subsubsection{Threshold based report}

Generate report of machines based on distance from optimality points. Use customizable threshold. 
Results from the report will be used to calculate suggestions.

\subsubsection{Visual recognition}



\section{Methodology and setup description}

\section{Algorithm walkthrough}
\subsection{Calculate cost per hour for a given pricing scheme}
Results for ccs2.xlarge based on data published for AWS~\cite{AWS:2014} \par
\csvautotabular{out}
\subsection{Calculate intersection points to find out the best pricing scheme for a number of hours/day utilization}
%\includegraphics[width=\linewidth]{cph}
\subsection{Collect VM usage data}
\subsection{Group usage metrics by machine}
\subsection{Calculate number of hours/day, distance from optimality points, CPU and memory utilization}
\subsection{Suggest changes to the least optimal VMs considering SLAs based on CPU and memory utilization}

\section{Summary}

%%%%%%%%%%%%%%%%%%%%%%
%%% OPTIONAL!!!
%%% CAPACITY PLANNING 
%%% STRATEGIES    
%%%%%%%%%%%%%%%%%%%%%%

%\chapter{Capacity Planning Strategies}

%\section{Peak-to-mean ratio based resource assignment}

%\section{Only heavy instances}

%%%%%%%%%%%%%%%%%%%%%%
%%% CONCLUSION 
%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion and Future Work}

%%%%%%%%%%%%%%%%%%%%%%
%%% REFERENCES 
%%%%%%%%%%%%%%%%%%%%%%

\newpage
\begin{thebibliography}{99}
\bibitem{spark} https://spark.apache.org
\bibitem{googleTrace} https://code.google.com/p/googleclusterdata
\bibitem{AWS:2014} http://forecastcloudy.net/2012/04/02/amazon-web-services-aws-ec2-pricing-data/ https://a0.awsstatic.com/pricing/1/deprecated/ec2/ri-light-linux.json https://a0.awsstatic.com/pricing/1/deprecated/ec2/ri-medium-linux.json https://a0.awsstatic.com/pricing/1/deprecated/ec2/ri-heavy-linux.json
\end{thebibliography}
\label{endpage}

\end{document}

\end{article}